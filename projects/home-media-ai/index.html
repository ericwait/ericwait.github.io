<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v4.16.19"><!-- Primary Meta Tags --><title></title><meta name="title"><meta name="description" content="Principal Data Scientist | GPU/ML Systems Engineer | Physics-Informed AI Specialist"><link rel="canonical" href="https://ericwait.com/projects/home-media-ai/"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://ericwait.com/projects/home-media-ai/"><meta property="og:title"><meta property="og:description" content="Principal Data Scientist | GPU/ML Systems Engineer | Physics-Informed AI Specialist"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://ericwait.com/projects/home-media-ai/"><meta property="twitter:title"><meta property="twitter:description" content="Principal Data Scientist | GPU/ML Systems Engineer | Physics-Informed AI Specialist"><!-- Fonts --><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800;900&display=swap" rel="stylesheet"><link rel="stylesheet" href="/_astro/full_journey.DiRwwqiG.css">
<link rel="stylesheet" href="/_astro/full_journey.B6Jj2yN9.css"><script type="module">const e=typeof localStorage<"u"&&localStorage.getItem("theme")?localStorage.getItem("theme"):window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light";e==="dark"?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark");e&&window.localStorage.setItem("theme",e);const m=()=>{const t=document.documentElement;t.classList.toggle("dark");const n=t.classList.contains("dark");localStorage.setItem("theme",n?"dark":"light");const l=document.getElementById("mobile-theme-label");l&&(l.textContent=n?"Dark":"Light")};document.getElementById("theme-toggle")?.addEventListener("click",m);document.getElementById("mobile-theme-toggle")?.addEventListener("click",m);document.getElementById("mobile-menu-button")?.addEventListener("click",()=>{document.getElementById("mobile-menu")?.classList.toggle("hidden")});const o=document.getElementById("mobile-theme-label");o&&(o.textContent=e==="dark"?"Dark":"Light");
</script></head> <body class="min-h-screen flex flex-col"> <nav class="fixed top-0 left-0 right-0 z-50 bg-white/80 dark:bg-gray-900/80 backdrop-blur-md border-b border-gray-200 dark:border-gray-800"> <div class="container"> <div class="flex items-center justify-between h-16"> <!-- Logo/Name --> <a href="/" class="text-xl font-bold text-gray-900 dark:text-white hover:text-primary-600 dark:hover:text-primary-400 transition-colors">
Eric Wait
</a> <!-- Desktop Navigation --> <div class="hidden md:flex items-center space-x-8"> <a href="/about" class="text-sm font-medium transition-colors text-gray-700 dark:text-gray-300 hover:text-primary-600 dark:hover:text-primary-400"> About </a><a href="/projects" class="text-sm font-medium transition-colors text-primary-600 dark:text-primary-400"> Projects </a><a href="/publications" class="text-sm font-medium transition-colors text-gray-700 dark:text-gray-300 hover:text-primary-600 dark:hover:text-primary-400"> Publications </a><a href="/photography" class="text-sm font-medium transition-colors text-gray-700 dark:text-gray-300 hover:text-primary-600 dark:hover:text-primary-400"> Photography </a> <!-- Theme Toggle --> <button id="theme-toggle" type="button" class="p-2 rounded-lg bg-gray-100 dark:bg-gray-800 hover:bg-gray-200 dark:hover:bg-gray-700 transition-colors" aria-label="Toggle theme"> <svg id="theme-toggle-light-icon" class="w-5 h-5 hidden dark:block" fill="currentColor" viewBox="0 0 20 20"> <path d="M10 2a1 1 0 011 1v1a1 1 0 11-2 0V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95l.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707a1 1 0 11-1.414-1.414l.707-.707a1 1 0 011.414 0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707a1 1 0 00-1.414 1.414l.707.707zm1.414 8.486l-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z"></path> </svg> <svg id="theme-toggle-dark-icon" class="w-5 h-5 block dark:hidden" fill="currentColor" viewBox="0 0 20 20"> <path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"></path> </svg> </button> </div> <!-- Mobile Menu Button --> <button id="mobile-menu-button" type="button" class="md:hidden p-2 rounded-lg bg-gray-100 dark:bg-gray-800 hover:bg-gray-200 dark:hover:bg-gray-700 transition-colors" aria-label="Toggle menu"> <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path> </svg> </button> </div> </div> <!-- Mobile Menu --> <div id="mobile-menu" class="hidden md:hidden border-t border-gray-200 dark:border-gray-800"> <div class="container py-4 space-y-3"> <a href="/about" class="block px-4 py-2 rounded-lg text-base font-medium transition-colors text-gray-700 dark:text-gray-300 hover:bg-gray-100 dark:hover:bg-gray-800"> About </a><a href="/projects" class="block px-4 py-2 rounded-lg text-base font-medium transition-colors bg-primary-50 dark:bg-primary-900/20 text-primary-600 dark:text-primary-400"> Projects </a><a href="/publications" class="block px-4 py-2 rounded-lg text-base font-medium transition-colors text-gray-700 dark:text-gray-300 hover:bg-gray-100 dark:hover:bg-gray-800"> Publications </a><a href="/photography" class="block px-4 py-2 rounded-lg text-base font-medium transition-colors text-gray-700 dark:text-gray-300 hover:bg-gray-100 dark:hover:bg-gray-800"> Photography </a> <button id="mobile-theme-toggle" type="button" class="w-full flex items-center justify-between px-4 py-2 rounded-lg text-base font-medium text-gray-700 dark:text-gray-300 hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors"> <span>Theme</span> <span id="mobile-theme-label" class="text-sm">Light</span> </button> </div> </div> </nav>  <main class="flex-1 mt-16">  <article class="section" data-astro-cid-scuu7fyy> <div class="container max-w-4xl" data-astro-cid-scuu7fyy> <!-- Header --> <header class="mb-12" data-astro-cid-scuu7fyy> <h1 class="text-4xl md:text-5xl font-bold mb-4" data-astro-cid-scuu7fyy>  </h1>  </header> <!-- Content --> <div class="content-body" data-astro-cid-scuu7fyy> <h2 id="title-home-media-aidate-2025-11-02featured_image-imagescameras2pngdescription-open-source-ml-system-for-organizing-and-curating-200k-personal-photo-collections">title: “Home Media AI”
date: 2025-11-02
featured_image: ‘/images/cameras2.png’
description: “Open-source ML system for organizing and curating 200K+ personal photo collections”</h2>
<h2 id="quick-takeaways">Quick Takeaways</h2>
<p><strong>Problem:</strong> Finding “great photos” in 200K+ personal collections—combining objective technical metrics (sharpness, exposure) with subjective aesthetic judgment</p>
<p><strong>Solution:</strong> Open-source ML system using computer vision, YOLO object detection, and hierarchical classification to surface best images</p>
<p><strong>Philosophy:</strong> The intersection of art and engineering—translating professional photography judgment into algorithmic rules that scale</p>
<p><strong>Key Insight:</strong> ML should multiply human capability, not replace it—review top 2,000 candidates instead of 20,000 images</p>
<p><strong>Technical Approach:</strong> Python/SQLAlchemy, MariaDB, OpenCV/Pillow, YOLO for people/pet detection, scikit-learn for quality models</p>
<p><strong>Status:</strong> Active development (43+ commits), verified on 700K+ file collections, open source on GitHub</p>
<p><a href="https://github.com/ericwait/home-media-ai">GitHub →</a> | <a href="../photos">Related: Photography Philosophy →</a></p>
<hr/>
<h2 id="the-challenge-finding-signal-in-200000-images">The Challenge: Finding Signal in 200,000 Images</h2>
<p>Most families accumulate thousands of photos each year. My household averages 20,000+ annually—vacations, birthdays, pets, everyday moments. That’s over 200,000 images spanning a decade.</p>
<p>Every year, my wife goes through this entire collection to curate our family calendar. She’s looking for:</p>
<ul>
<li><strong>Technical quality</strong> - Sharp focus, good exposure, balanced composition</li>
<li><strong>Aesthetic appeal</strong> - Compelling moments, good light, visual interest</li>
<li><strong>Semantic relevance</strong> - Birthday photos for birthday months, holiday images for December, pictures featuring specific people or pets</li>
</ul>
<p>It’s meaningful work—these images tell our family’s story. But manually reviewing 20,000 images is exhausting.</p>
<p><strong>The core problem:</strong> How do you automatically identify “great photos” when “great” combines objective technical metrics (sharpness, exposure) with subjective aesthetic judgment (compelling composition, emotional impact)?</p>
<hr/>
<h2 id="the-solution-ml-powered-photo-curation">The Solution: ML-Powered Photo Curation</h2>
<p><strong><a href="https://github.com/ericwait/home-media-ai">Home Media AI</a></strong> is an open-source system that combines computer vision, machine learning, and hierarchical classification to surface the best images from massive personal collections.</p>
<h3 id="core-capabilities">Core Capabilities</h3>
<p><strong>1. Automated Quality Assessment</strong></p>
<ul>
<li>Technical metrics: sharpness (edge detection), exposure balance, noise levels</li>
<li>Compositional analysis: rule-of-thirds compliance, negative space, subject positioning</li>
<li>Duplicate and near-duplicate detection (checksummed file tracking)</li>
</ul>
<p><strong>2. Rich Semantic Search</strong></p>
<ul>
<li>Hierarchical classification support (people, pets, places, events)</li>
<li>Works with any taxonomy: biological classification (World Flora Online integration), geographic hierarchies, custom family categories</li>
<li>Relationship tracking: “Find photos of [person] at [location] during [time period]”</li>
</ul>
<p><strong>3. Scale-Tested Architecture</strong></p>
<ul>
<li>Verified to handle 700K+ file collections</li>
<li>Files stay in original locations—metadata tracked separately</li>
<li>Relationship mapping between originals and edited versions</li>
<li>Cross-platform: Windows, Mac, Linux path support</li>
</ul>
<p><strong>4. Long-Term Reliability</strong></p>
<ul>
<li>Everything checksummed and versioned</li>
<li>Auditable: never moves or deletes files</li>
<li>Handles duplicate detection across drives and backups</li>
</ul>
<h3 id="the-goal-multiply-human-curation">The Goal: Multiply Human Curation</h3>
<p>The system doesn’t replace human judgment—it multiplies it. Instead of reviewing 20,000 images, curators review the top 2,000 candidates the ML system surfaces. The human still makes the final decision, but with 90% less exhaustion.</p>
<hr/>
<h2 id="technical-architecture">Technical Architecture</h2>
<h3 id="backend-stack">Backend Stack</h3>
<ul>
<li><strong>Python</strong> with <strong>SQLAlchemy ORM</strong> for flexible data modeling</li>
<li><strong>MariaDB 10.11+</strong> (UTF-8mb4 support for international text/emoji)</li>
<li><strong>NumPy/Pandas</strong> for data processing pipelines</li>
<li><strong>Scikit-learn</strong> for ML classification models</li>
</ul>
<h3 id="media-processing--ml">Media Processing &amp; ML</h3>
<ul>
<li><strong>OpenCV</strong> for image analysis (edge detection, histogram analysis, feature extraction)</li>
<li><strong>Pillow</strong> for format handling and EXIF data extraction</li>
<li><strong>exifread</strong> for metadata parsing (camera settings, timestamps, GPS)</li>
<li><strong>YOLO (You Only Look Once)</strong> for real-time object detection and classification
<ul>
<li>Identifying people, pets, and objects in images</li>
<li>Pre-trained models fine-tuned on personal photo collection</li>
<li>Enables semantic search: “Find photos with our dog at the beach”</li>
</ul>
</li>
</ul>
<h3 id="development-environment">Development Environment</h3>
<ul>
<li><strong>Jupyter Lab</strong> for exploratory data analysis and model tuning</li>
<li><strong>Mamba</strong> for reproducible environment management</li>
<li>Phase-based development: Core discovery (Phase I) → ML models (Phase II) → Web interface (Phase III)</li>
</ul>
<h3 id="database-design-philosophy">Database Design Philosophy</h3>
<p>The system uses a <strong>relational database to track media and their relationships to classification hierarchies</strong>:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8;overflow-x:auto" tabindex="0" data-language="plaintext"><code><span class="line"><span>MediaFiles (checksummed tracking)</span></span>
<span class="line"><span>  ↓</span></span>
<span class="line"><span>MediaRelationships (originals → edits)</span></span>
<span class="line"><span>  ↓</span></span>
<span class="line"><span>ClassificationLinks (files → hierarchical taxonomies)</span></span>
<span class="line"><span>  ↓</span></span>
<span class="line"><span>TaxonomyNodes (hierarchical classification systems)</span></span>
<span class="line"><span></span></span></code></pre>
<p>This design allows:</p>
<ul>
<li>Multiple simultaneous classification systems per media item (e.g., a photo can be tagged with biological taxonomy AND family event categories)</li>
<li>Version tracking (linking RAW → edited JPG)</li>
<li>Flexible hierarchies (person/pet names, locations, dates, custom categories)</li>
</ul>
<hr/>
<h2 id="the-intersection-art-meets-engineering">The Intersection: Art Meets Engineering</h2>
<p>This project embodies the “intersection philosophy” that drives my technical work:</p>
<p><strong>Artistic Training → Technical Implementation</strong></p>
<p>My background as a professional photographer taught me what makes a photo compelling:</p>
<ul>
<li>Compositional balance (rule-of-thirds, leading lines, negative space)</li>
<li>Light quality (golden hour, directional lighting, shadow/highlight balance)</li>
<li>The decisive moment (timing, expression, action peaks)</li>
</ul>
<p>Translating these intuitions into algorithmic rules is the challenge:</p>
<ul>
<li>“Good composition” → edge detection patterns, symmetry analysis, subject positioning heuristics</li>
<li>“Compelling light” → histogram analysis, dynamic range metrics, color temperature evaluation</li>
<li>“The decisive moment” → temporal burst analysis, facial expression detection, motion blur assessment</li>
</ul>
<p><strong>Human-Centered ML</strong></p>
<p>The system is designed around a core insight: <strong>ML should amplify human capability, not replace human judgment</strong>.</p>
<p>My wife has curated our family photos for years—she has taste, context, and emotional connection that no algorithm can replicate. The goal isn’t to automate her out of the process. It’s to give her back hours of her life by surfacing candidates worth considering.</p>
<p>This philosophy applies to all my ML work: physics-informed neural networks that encode domain knowledge, GPU-accelerated pipelines that augment scientist workflows, explainable models that support human decision-making.</p>
<hr/>
<h2 id="implementation-status--roadmap">Implementation Status &amp; Roadmap</h2>
<h3 id="phase-i-core-infrastructure-in-progress">Phase I: Core Infrastructure (In Progress)</h3>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" checked disabled/> Database schema design and migration system</li>
<li class="task-list-item"><input type="checkbox" checked disabled/> Media file discovery and checksumming</li>
<li class="task-list-item"><input type="checkbox" checked disabled/> Cross-platform path handling</li>
<li class="task-list-item"><input type="checkbox" checked disabled/> Duplicate detection logic</li>
<li class="task-list-item"><input type="checkbox" checked disabled/> Configuration management</li>
<li class="task-list-item"><input type="checkbox" disabled/> Complete EXIF/metadata extraction pipeline</li>
</ul>
<h3 id="phase-ii-ml-classification-in-progress">Phase II: ML Classification (In Progress)</h3>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" disabled/> Quality assessment models (technical metrics)</li>
<li class="task-list-item"><input type="checkbox" disabled/> Aesthetic scoring (compositional analysis)</li>
<li class="task-list-item"><input type="checkbox" checked disabled/> <strong>YOLO-based object detection</strong> - Real-time identification of people, pets, and objects
<ul>
<li>Fine-tuning pre-trained models on personal photo collection</li>
<li>Enabling semantic queries: “Photos with [person] and [pet]”</li>
<li>Bounding box extraction for face/subject cropping</li>
</ul>
</li>
<li class="task-list-item"><input type="checkbox" disabled/> Hierarchical classification integration</li>
<li class="task-list-item"><input type="checkbox" disabled/> Model training pipeline for quality/aesthetic scoring</li>
</ul>
<h3 id="phase-iii-user-interface-future">Phase III: User Interface (Future)</h3>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" disabled/> Web-based curation interface</li>
<li class="task-list-item"><input type="checkbox" disabled/> Search and filter capabilities</li>
<li class="task-list-item"><input type="checkbox" disabled/> Calendar generation automation</li>
<li class="task-list-item"><input type="checkbox" disabled/> Batch export and sharing tools</li>
</ul>
<h3 id="phase-iv-community-features-future">Phase IV: Community Features (Future)</h3>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" disabled/> Shared classification taxonomies</li>
<li class="task-list-item"><input type="checkbox" disabled/> Pre-trained aesthetic models</li>
<li class="task-list-item"><input type="checkbox" disabled/> Plugin system for custom classifiers</li>
<li class="task-list-item"><input type="checkbox" disabled/> Documentation and tutorials</li>
</ul>
<hr/>
<h2 id="real-world-impact">Real-World Impact</h2>
<p><strong>Current Use Case:</strong> Family photo archival and calendar curation</p>
<ul>
<li>200K+ images spanning 10+ years</li>
<li>20K+ annual additions</li>
<li>Handles multiple cameras, phones, and formats</li>
<li>Preserves original files while tracking edits and versions</li>
</ul>
<p><strong>Potential Applications:</strong></p>
<ul>
<li><strong>Nature photography organization</strong> - Integrate with biological taxonomies (World Flora Online, eBird)</li>
<li><strong>Travel documentation</strong> - Hierarchical geographic classification</li>
<li><strong>Technical equipment cataloging</strong> - Product photo organization</li>
<li><strong>Professional portfolio curation</strong> - Quality-based filtering for client galleries</li>
<li><strong>Digital archival projects</strong> - Long-term family/organizational media preservation</li>
</ul>
<hr/>
<h2 id="open-source--community">Open Source &amp; Community</h2>
<p>The project is <strong><a href="https://github.com/ericwait/home-media-ai">open source on GitHub</a></strong> with active development (43+ commits).</p>
<p><strong>Why open source?</strong></p>
<ul>
<li>Personal media archival is a universal challenge</li>
<li>Shared taxonomies and models benefit everyone</li>
<li>Community contributions accelerate development</li>
<li>Transparency builds trust for family archival systems</li>
</ul>
<p><strong>Contributing:</strong>
The project welcomes contributions—whether suggesting features, reporting issues, contributing classification taxonomies, or improving ML models. Check the repository for current priorities and development guidelines.</p>
<hr/>
<h2 id="technical-highlights">Technical Highlights</h2>
<h3 id="modern-ml-yolo-for-object-detection">Modern ML: YOLO for Object Detection</h3>
<ul>
<li>Real-time object detection using YOLO (You Only Look Once)</li>
<li>Pre-trained on COCO dataset, fine-tuned on personal collection</li>
<li>Enables semantic search beyond simple keyword tags</li>
<li>Example queries: “Photos with both kids and the dog”, “Images featuring specific people at specific locations”</li>
<li>Bounding box data stored for future cropping/thumbnail generation</li>
</ul>
<h3 id="scale-tested-design">Scale-Tested Design</h3>
<ul>
<li>Verified on 700K+ file collections</li>
<li>Efficient database indexing for fast queries</li>
<li>Incremental processing (only analyze new/changed files)</li>
</ul>
<h3 id="file-integrity">File Integrity</h3>
<ul>
<li>Checksummed tracking prevents duplicates</li>
<li>Never moves or deletes original files</li>
<li>Separate metadata database keeps files untouched</li>
</ul>
<h3 id="flexible-classification">Flexible Classification</h3>
<ul>
<li>Works with any hierarchical taxonomy</li>
<li>Example: World Flora Online (WFO) plant classification integrated</li>
<li>Custom taxonomies for family/personal categories</li>
</ul>
<h3 id="cross-platform">Cross-Platform</h3>
<ul>
<li>Native Windows, Mac, Linux path support</li>
<li>Handles network shares and external drives</li>
<li>Docker deployment for portability</li>
</ul>
<hr/>
<h2 id="lessons-learned-building-ml-for-real-users">Lessons Learned: Building ML for Real Users</h2>
<h3 id="1-perfect-is-the-enemy-of-shipped">1. Perfect is the Enemy of Shipped</h3>
<p>Early versions focused on sophisticated aesthetic models. Reality: even basic quality metrics (sharpness, exposure) provide 80% of the value. Ship incrementally.</p>
<h3 id="2-respect-user-workflows">2. Respect User Workflows</h3>
<p>Users already have folder structures, backup routines, and editing workflows. Don’t force them to change. The “files stay put” design principle came from listening to real needs.</p>
<h3 id="3-explain-decisions">3. Explain Decisions</h3>
<p>ML models that rank photos should explain <em>why</em>. “High quality” is less useful than “Sharp focus, good exposure, rule-of-thirds composition”. Explainability builds trust.</p>
<h3 id="4-build-for-maintenance">4. Build for Maintenance</h3>
<p>Personal photo collections span decades. The system must be maintainable long-term. Clear database schema, versioned migrations, and minimal dependencies matter.</p>
<p>These lessons apply beyond family photos—they’re principles for any production ML system.</p>
<hr/>
<h2 id="future-directions">Future Directions</h2>
<h3 id="short-term">Short-Term</h3>
<ul>
<li>Complete Phase I media discovery pipeline</li>
<li>Implement basic quality assessment models</li>
<li>Build proof-of-concept web interface</li>
</ul>
<h3 id="medium-term">Medium-Term</h3>
<ul>
<li>Train aesthetic models on curated personal dataset</li>
<li>Integrate face detection for person-based search</li>
<li>Automated calendar generation from top-ranked images</li>
</ul>
<h3 id="long-term">Long-Term</h3>
<ul>
<li>Federated learning across multiple family collections (privacy-preserving)</li>
<li>Mobile app for field tagging during photography</li>
<li>Integration with cloud photo services (Google Photos, iCloud)</li>
<li>Community-curated aesthetic models</li>
</ul>
<hr/>
<h2 id="links--resources">Links &amp; Resources</h2>
<p><strong>GitHub Repository:</strong> <a href="https://github.com/ericwait/home-media-ai">https://github.com/ericwait/home-media-ai</a></p>
<p><strong>Related Projects:</strong></p>
<ul>
<li><a href="./hydra">Hydra Image Processor</a> - GPU-accelerated image analysis library</li>
<li><a href="../photos">Photography</a> - Artistic background and philosophy</li>
</ul>
<p><strong>Technologies:</strong></p>
<ul>
<li>Python, SQLAlchemy, MariaDB</li>
<li>OpenCV, Pillow, NumPy, Pandas</li>
<li>YOLO (object detection), Scikit-learn, Jupyter Lab</li>
</ul>
<hr/>
<h2 id="how-this-connects">How This Connects</h2>
<p><strong>Intersection Philosophy:</strong> See how art meets engineering across my work → <a href="../photos#the-intersection-seeing-patterns-from-landscapes-to-algorithms">Photography</a></p>
<p><strong>Human-Centered ML:</strong> Explore systems that multiply human capability → <a href="../#-human-centered-ai-design">Home page</a></p>
<p><strong>Professional Photography Background:</strong> Learn how artistic training shapes technical work → <a href="../photos">Photography</a> and <a href="../about/full_journey#professional-photography">Full Journey</a></p>
<p><strong>Building What Lasts:</strong> Compare with long-term development practices → <a href="./matlab-utilities">MATLAB Utilities</a></p>
<p><strong>Technical Approach:</strong> See related ML systems and GPU acceleration → <a href="./hydra">Hydra Image Processor</a></p>
<p><strong>Design Philosophy:</strong> Read about making optimization accessible → <a href="../about#how-i-build-long-term-excellence">About</a></p>
<hr/>
<p><em>Building tools that respect both the art and the scale of personal photography—because every family’s story deserves to be found.</em></p> </div> </div> </article>  </main> <footer class="bg-gray-50 dark:bg-gray-900 border-t border-gray-200 dark:border-gray-800"> <div class="container py-12"> <div class="grid grid-cols-1 md:grid-cols-3 gap-8"> <!-- About --> <div> <h3 class="text-lg font-bold mb-4">Eric Wait</h3> <p class="text-gray-600 dark:text-gray-400 text-sm">
Principal Data Scientist | GPU/ML Systems Engineer | Physics-Informed AI Specialist
</p> </div> <!-- Quick Links --> <div> <h3 class="text-lg font-bold mb-4">Quick Links</h3> <ul class="space-y-2"> <li><a href="/about" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 text-sm transition-colors">About</a></li> <li><a href="/projects" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 text-sm transition-colors">Projects</a></li> <li><a href="/publications" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 text-sm transition-colors">Publications</a></li> <li><a href="/photography" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 text-sm transition-colors">Photography</a></li> </ul> </div> <!-- Social --> <div> <h3 class="text-lg font-bold mb-4">Connect</h3> <div class="flex space-x-4"> <a href="https://github.com/ericwait" target="_blank" rel="noopener noreferrer" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 transition-colors" aria-label="GitHub"> <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"> <path fill-rule="evenodd" d="M12 2C6.477 2 2 6.484 2 12.017c0 4.425 2.865 8.18 6.839 9.504.5.092.682-.217.682-.483 0-.237-.008-.868-.013-1.703-2.782.605-3.369-1.343-3.369-1.343-.454-1.158-1.11-1.466-1.11-1.466-.908-.62.069-.608.069-.608 1.003.07 1.531 1.032 1.531 1.032.892 1.53 2.341 1.088 2.91.832.092-.647.35-1.088.636-1.338-2.22-.253-4.555-1.113-4.555-4.951 0-1.093.39-1.988 1.029-2.688-.103-.253-.446-1.272.098-2.65 0 0 .84-.27 2.75 1.026A9.564 9.564 0 0112 6.844c.85.004 1.705.115 2.504.337 1.909-1.296 2.747-1.027 2.747-1.027.546 1.379.202 2.398.1 2.651.64.7 1.028 1.595 1.028 2.688 0 3.848-2.339 4.695-4.566 4.943.359.309.678.92.678 1.855 0 1.338-.012 2.419-.012 2.747 0 .268.18.58.688.482A10.019 10.019 0 0022 12.017C22 6.484 17.522 2 12 2z" clip-rule="evenodd"></path> </svg>    </a><a href="https://www.linkedin.com/in/ericwaitinfo/" target="_blank" rel="noopener noreferrer" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 transition-colors" aria-label="LinkedIn">  <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"> <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path> </svg>   </a><a href="https://twitter.com/ericwait" target="_blank" rel="noopener noreferrer" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 transition-colors" aria-label="Twitter">   <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"> <path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"></path> </svg>  </a><a href="https://www.instagram.com/eric.wait/" target="_blank" rel="noopener noreferrer" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 transition-colors" aria-label="Instagram">    <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"> <path d="M12 2.163c3.204 0 3.584.012 4.85.07 3.252.148 4.771 1.691 4.919 4.919.058 1.265.069 1.645.069 4.849 0 3.205-.012 3.584-.069 4.849-.149 3.225-1.664 4.771-4.919 4.919-1.266.058-1.644.07-4.85.07-3.204 0-3.584-.012-4.849-.07-3.26-.149-4.771-1.699-4.919-4.92-.058-1.265-.07-1.644-.07-4.849 0-3.204.013-3.583.07-4.849.149-3.227 1.664-4.771 4.919-4.919 1.266-.057 1.645-.069 4.849-.069zm0-2.163c-3.259 0-3.667.014-4.947.072-4.358.2-6.78 2.618-6.98 6.98-.059 1.281-.073 1.689-.073 4.948 0 3.259.014 3.668.072 4.948.2 4.358 2.618 6.78 6.98 6.98 1.281.058 1.689.072 4.948.072 3.259 0 3.668-.014 4.948-.072 4.354-.2 6.782-2.618 6.979-6.98.059-1.28.073-1.689.073-4.948 0-3.259-.014-3.667-.072-4.947-.196-4.354-2.617-6.78-6.979-6.98-1.281-.059-1.69-.073-4.949-.073zm0 5.838c-3.403 0-6.162 2.759-6.162 6.162s2.759 6.163 6.162 6.163 6.162-2.759 6.162-6.163c0-3.403-2.759-6.162-6.162-6.162zm0 10.162c-2.209 0-4-1.79-4-4 0-2.209 1.791-4 4-4s4 1.791 4 4c0 2.21-1.791 4-4 4zm6.406-11.845c-.796 0-1.441.645-1.441 1.44s.645 1.44 1.441 1.44c.795 0 1.439-.645 1.439-1.44s-.644-1.44-1.439-1.44z"></path> </svg> </a> </div> </div> </div> <!-- Copyright --> <div class="mt-8 pt-8 border-t border-gray-200 dark:border-gray-800 text-center"> <p class="text-sm text-gray-600 dark:text-gray-400">
© 2025 Eric Wait. All rights reserved.
</p> </div> </div> </footer> </body></html> 