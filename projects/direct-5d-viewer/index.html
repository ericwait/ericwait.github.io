<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v4.16.19"><!-- Primary Meta Tags --><title></title><meta name="title"><meta name="description" content="Principal Data Scientist | GPU/ML Systems Engineer | Physics-Informed AI Specialist"><link rel="canonical" href="https://ericwait.com/projects/direct-5d-viewer/"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://ericwait.com/projects/direct-5d-viewer/"><meta property="og:title"><meta property="og:description" content="Principal Data Scientist | GPU/ML Systems Engineer | Physics-Informed AI Specialist"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://ericwait.com/projects/direct-5d-viewer/"><meta property="twitter:title"><meta property="twitter:description" content="Principal Data Scientist | GPU/ML Systems Engineer | Physics-Informed AI Specialist"><!-- Fonts --><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800;900&display=swap" rel="stylesheet"><link rel="stylesheet" href="/_astro/full_journey.DiRwwqiG.css">
<link rel="stylesheet" href="/_astro/full_journey.BfgPfsgX.css"><script type="module">const e=typeof localStorage<"u"&&localStorage.getItem("theme")?localStorage.getItem("theme"):window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light";e==="dark"?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark");e&&window.localStorage.setItem("theme",e);const m=()=>{const t=document.documentElement;t.classList.toggle("dark");const n=t.classList.contains("dark");localStorage.setItem("theme",n?"dark":"light");const l=document.getElementById("mobile-theme-label");l&&(l.textContent=n?"Dark":"Light")};document.getElementById("theme-toggle")?.addEventListener("click",m);document.getElementById("mobile-theme-toggle")?.addEventListener("click",m);document.getElementById("mobile-menu-button")?.addEventListener("click",()=>{document.getElementById("mobile-menu")?.classList.toggle("hidden")});const o=document.getElementById("mobile-theme-label");o&&(o.textContent=e==="dark"?"Dark":"Light");
</script></head> <body class="min-h-screen flex flex-col"> <nav class="fixed top-0 left-0 right-0 z-50 bg-white/80 dark:bg-gray-900/80 backdrop-blur-md border-b border-gray-200 dark:border-gray-800"> <div class="container"> <div class="flex items-center justify-between h-16"> <!-- Logo/Name --> <a href="/" class="text-xl font-bold text-gray-900 dark:text-white hover:text-primary-600 dark:hover:text-primary-400 transition-colors">
Eric Wait
</a> <!-- Desktop Navigation --> <div class="hidden md:flex items-center space-x-8"> <a href="/about" class="text-sm font-medium transition-colors text-gray-700 dark:text-gray-300 hover:text-primary-600 dark:hover:text-primary-400"> About </a><a href="/projects" class="text-sm font-medium transition-colors text-primary-600 dark:text-primary-400"> Projects </a><a href="/publications" class="text-sm font-medium transition-colors text-gray-700 dark:text-gray-300 hover:text-primary-600 dark:hover:text-primary-400"> Publications </a><a href="/photography" class="text-sm font-medium transition-colors text-gray-700 dark:text-gray-300 hover:text-primary-600 dark:hover:text-primary-400"> Photography </a> <!-- Theme Toggle --> <button id="theme-toggle" type="button" class="p-2 rounded-lg bg-gray-100 dark:bg-gray-800 hover:bg-gray-200 dark:hover:bg-gray-700 transition-colors" aria-label="Toggle theme"> <svg id="theme-toggle-light-icon" class="w-5 h-5 hidden dark:block" fill="currentColor" viewBox="0 0 20 20"> <path d="M10 2a1 1 0 011 1v1a1 1 0 11-2 0V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95l.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707a1 1 0 11-1.414-1.414l.707-.707a1 1 0 011.414 0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707a1 1 0 00-1.414 1.414l.707.707zm1.414 8.486l-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z"></path> </svg> <svg id="theme-toggle-dark-icon" class="w-5 h-5 block dark:hidden" fill="currentColor" viewBox="0 0 20 20"> <path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"></path> </svg> </button> </div> <!-- Mobile Menu Button --> <button id="mobile-menu-button" type="button" class="md:hidden p-2 rounded-lg bg-gray-100 dark:bg-gray-800 hover:bg-gray-200 dark:hover:bg-gray-700 transition-colors" aria-label="Toggle menu"> <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path> </svg> </button> </div> </div> <!-- Mobile Menu --> <div id="mobile-menu" class="hidden md:hidden border-t border-gray-200 dark:border-gray-800"> <div class="container py-4 space-y-3"> <a href="/about" class="block px-4 py-2 rounded-lg text-base font-medium transition-colors text-gray-700 dark:text-gray-300 hover:bg-gray-100 dark:hover:bg-gray-800"> About </a><a href="/projects" class="block px-4 py-2 rounded-lg text-base font-medium transition-colors bg-primary-50 dark:bg-primary-900/20 text-primary-600 dark:text-primary-400"> Projects </a><a href="/publications" class="block px-4 py-2 rounded-lg text-base font-medium transition-colors text-gray-700 dark:text-gray-300 hover:bg-gray-100 dark:hover:bg-gray-800"> Publications </a><a href="/photography" class="block px-4 py-2 rounded-lg text-base font-medium transition-colors text-gray-700 dark:text-gray-300 hover:bg-gray-100 dark:hover:bg-gray-800"> Photography </a> <button id="mobile-theme-toggle" type="button" class="w-full flex items-center justify-between px-4 py-2 rounded-lg text-base font-medium text-gray-700 dark:text-gray-300 hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors"> <span>Theme</span> <span id="mobile-theme-label" class="text-sm">Light</span> </button> </div> </div> </nav>  <main class="flex-1 mt-16">  <article class="section" data-astro-cid-scuu7fyy> <div class="container max-w-4xl" data-astro-cid-scuu7fyy> <!-- Header --> <header class="mb-12" data-astro-cid-scuu7fyy> <h1 class="text-4xl md:text-5xl font-bold mb-4" data-astro-cid-scuu7fyy>  </h1>  </header> <!-- Content --> <div class="content-body" data-astro-cid-scuu7fyy> <h2 id="title-direct-5d-viewerdate-2024-12-04featured_image-imagescircuitspngdescription-gpu-accelerated-interactive-visualization-of-5d-microscopy-data-leveraging-human-visual-perception">title: “Direct 5D Viewer”
date: 2024-12-04
featured_image: ‘/images/circuits.png’
description: “GPU-accelerated interactive visualization of 5D microscopy data leveraging human visual perception”</h2>
<h2 id="quick-takeaways">Quick Takeaways</h2>
<p><strong>Problem:</strong> 5D microscopy data (x, y, z, channels, time) hard to understand—traditional projections lose depth information and create false conclusions</p>
<p><strong>Solution:</strong> GPU-accelerated interactive visualization leveraging human visual perception (motion detection, depth sensitivity, pattern recognition)</p>
<p><strong>Impact:</strong> Used by 170+ scientists at HHMI Janelia, enabled discoveries in <em>Nature</em> and <em>Nature Communications</em>, prevented algorithmic errors through visual validation</p>
<p><strong>Philosophy:</strong> Human-centered design—technology should amplify human capability (visual perception) rather than replace it</p>
<p><strong>Key Innovation:</strong> Real-time rendering with adjustable-speed temporal playback, stereoscopic 3D, polygon overlay for computational validation</p>
<p><strong>Status:</strong> Active development (607 commits, v2.0 December 2024), integrated with Hydra Image Processor, MATLAB accessible</p>
<p><a href="https://github.com/ericwait/direct-5D-viewer">GitHub →</a> | <a href="https://www.mathworks.com/matlabcentral/fileexchange/176924-direct-5d-viewer">MATLAB File Exchange →</a> | <a href="./hydra">Related: Hydra →</a></p>
<hr/>
<h2 id="the-challenge-leveraging-human-vision-for-scientific-insight">The Challenge: Leveraging Human Vision for Scientific Insight</h2>
<p>Complex microscope data is hard to comprehend. We capture terabyte-scale datasets with five dimensions: x, y, z (spatial), channels (spectral/fluorescence), and time. Analyzing this data computationally is one challenge—but <strong>understanding</strong> it requires human insight.</p>
<p>Here’s the paradox: <strong>Our visual systems are the highest-performance pattern recognition systems on the planet</strong>, evolved over millions of years and trained from birth. Yet most scientific visualization tools don’t leverage this capability effectively.</p>
<p><strong>The core problem:</strong> How do you present 5-dimensional scientific data in a way that harnesses the strengths of human vision—motion detection, contrast sensitivity, depth perception—without introducing false conclusions?</p>
<hr/>
<h2 id="the-vision-problem-when-visualization-misleads">The Vision Problem: When Visualization Misleads</h2>
<p>Traditional approaches to visualizing 3D microscopy data often use <strong>maximum intensity projections</strong>—collapsing the depth dimension into a 2D image. This creates a critical problem:</p>
<p><strong>Depth is lost. Objects that are far apart in 3D space appear adjacent in the projection.</strong></p>
<p>Researchers can draw false conclusions about spatial relationships, contact between structures, or temporal sequences of events. The visualization becomes a liability rather than an asset.</p>
<p><strong>The solution must satisfy contradictory requirements:</strong></p>
<ul>
<li>Show <strong>context</strong> (how structures relate across the full volume)</li>
<li>Preserve <strong>depth information</strong> (true 3D spatial relationships)</li>
<li>Enable <strong>real-time interaction</strong> (rotate, zoom, temporal playback)</li>
<li>Support <strong>validation</strong> (verify computational results against original data)</li>
<li>Be <strong>accessible</strong> (integrate with existing scientific workflows)</li>
</ul>
<hr/>
<h2 id="the-solution-gpu-accelerated-interactive-visualization">The Solution: GPU-Accelerated Interactive Visualization</h2>
<p><strong><a href="https://github.com/ericwait/direct-5D-viewer">Direct 5D Viewer</a></strong> is a DirectX-powered visualization system that leverages modern GPU capabilities to present complex microscopy data in a form that exploits human visual strengths.</p>
<h3 id="core-capabilities">Core Capabilities</h3>
<p><strong>1. True 3D Rendering with Object Occlusion</strong></p>
<ul>
<li>Volume rendering with proper depth occlusion (near objects block far objects)</li>
<li>No false adjacency—spatial relationships preserved</li>
<li>Real-time rotation and navigation through 3D space</li>
</ul>
<p><strong>2. Adjustable-Speed Temporal Playback</strong></p>
<ul>
<li>Leverages human motion detection (our eyes evolved to detect movement)</li>
<li><strong>Slow playback highlights fast features</strong> - Rapid events (vesicle fusion, calcium waves) become visible when slowed down</li>
<li><strong>Fast playback emphasizes slow features</strong> - Gradual processes (cell migration, morphology changes) emerge when accelerated</li>
<li>Immediate recognition of dynamic patterns across different timescales</li>
</ul>
<p><strong>3. Stereoscopic 3D Support</strong></p>
<ul>
<li>True depth perception through stereo viewing</li>
<li>Further emphasizes spatial relationships</li>
<li>Reduces cognitive load when understanding complex 3D structures</li>
</ul>
<p><strong>4. Computational Validation Through Visualization</strong></p>
<ul>
<li><strong>Polygon embedding</strong> - Overlay computational results (segmentation boundaries, tracking paths) directly on original data</li>
<li>Immediate verification: “Does my algorithm’s output make sense given what I see?”</li>
<li>Prevents the trap of results that “make sense” abstractly but fail on real data</li>
</ul>
<p><strong>5. Advanced Coloring and Lighting</strong></p>
<ul>
<li>Distinguish individual objects through unique coloring</li>
<li>Multi-channel fluorescence data shown with biologically meaningful color mapping</li>
<li>Lighting models that enhance depth perception and structural detail</li>
</ul>
<p><strong>6. MATLAB Integration</strong></p>
<ul>
<li>Direct callable from MATLAB (the lingua franca of scientific computing)</li>
<li>Seamless workflow: analyze in MATLAB → visualize in 5D Viewer → iterate</li>
<li>No exporting files, no separate applications, no workflow friction</li>
</ul>
<hr/>
<h2 id="the-human-centered-design-philosophy">The Human-Centered Design Philosophy</h2>
<p>This project embodies a core principle: <strong>Technology should amplify human capability, not replace it.</strong></p>
<h3 id="why-human-visual-perception-matters">Why Human Visual Perception Matters</h3>
<p>Humans excel at:</p>
<ul>
<li><strong>Motion detection</strong> - We instantly notice movement in our peripheral vision</li>
<li><strong>Contrast sensitivity</strong> - We detect subtle intensity changes that algorithms miss</li>
<li><strong>Pattern recognition</strong> - We see structures in noisy data without explicit training</li>
<li><strong>Spatial reasoning</strong> - We understand 3D relationships intuitively</li>
</ul>
<p>Algorithms excel at:</p>
<ul>
<li><strong>Quantification</strong> - Measuring precise distances, volumes, intensities</li>
<li><strong>Reproducibility</strong> - Same input always produces same output</li>
<li><strong>Scale</strong> - Processing millions of data points consistently</li>
<li><strong>Explicit rules</strong> - Following defined criteria without bias</li>
</ul>
<p><strong>The Direct 5D Viewer creates a partnership:</strong> Algorithms do the heavy lifting (segmentation, tracking, measurement), humans validate and guide the analysis through interactive visualization.</p>
<h3 id="preventing-the-confirmation-bias-trap">Preventing the “Confirmation Bias” Trap</h3>
<p>A critical problem in scientific computing: <strong>Getting results that confirm our assumptions without verifying they reflect reality.</strong></p>
<p>Example scenario:</p>
<ol>
<li>Run cell segmentation algorithm</li>
<li>Get quantitative results: “Cell A volume = 1,234 µm³”</li>
<li>Accept the number because it’s precise and matches expectations</li>
<li><strong>Never verify the segmentation was actually correct</strong></li>
</ol>
<p><strong>The Direct 5D Viewer forces verification:</strong></p>
<ol>
<li>Run segmentation</li>
<li>Overlay segmentation boundaries on original microscopy data</li>
<li>Visually inspect: “Did the algorithm segment the right structure?”</li>
<li>Iterate if needed</li>
<li><strong>Only trust results after visual validation</strong></li>
</ol>
<p>This workflow catches errors like:</p>
<ul>
<li>Algorithm segments background noise as cells</li>
<li>Touching cells merged into single object</li>
<li>Dim structures missed entirely</li>
<li>Edge artifacts from image preprocessing</li>
</ul>
<p>By showing <strong>computational results directly on original data</strong>, the viewer prevents blind trust in algorithmic output.</p>
<hr/>
<h2 id="the-philosophy-seeing-is-understanding">The Philosophy: Seeing is Understanding</h2>
<p>The Direct 5D Viewer embodies a fundamental principle: <strong>Human insight guided by computational power yields discoveries neither could achieve alone.</strong></p>
<p>Algorithms process scale. Humans provide context, intuition, and biological knowledge. The best scientific tools create partnerships between the two.</p>
<p>By leveraging human visual perception—motion detection, depth sensitivity, pattern recognition—the viewer turns raw data into understanding. Not just numbers, but insight. Not just results, but validated truth.</p>
<p>Because in science, the most powerful analysis is the one you can <strong>see</strong> is correct.</p>
<p><em>“The purpose of computing is insight, not numbers.” — Richard Hamming</em></p>
<p>This viewer exists to turn terabytes of microscopy data into scientific insight—by respecting both the power of computation and the irreplaceable capability of human vision.</p>
<hr/>
<h2 id="real-world-applications">Real-World Applications</h2>
<h3 id="cellular-biology-research">Cellular Biology Research</h3>
<p><strong>Use Case:</strong> Tracking mitochondrial dynamics during cell division</p>
<ul>
<li>5D dataset: 3D volume, 2 fluorescence channels (mitochondria, nucleus), time series</li>
<li>Challenge: Understanding how mitochondria distribute during division</li>
<li>Solution: Time-lapse playback with stereoscopic viewing reveals spatial patterns</li>
<li>Outcome: Discovered asymmetric distribution patterns invisible in projections</li>
</ul>
<h3 id="drug-response-analysis">Drug Response Analysis</h3>
<p><strong>Use Case:</strong> Measuring cellular response to therapeutic compounds</p>
<ul>
<li>5D dataset: Multi-well plates (spatial), multiple drugs (channels), time-course</li>
<li>Challenge: Identifying which compounds affect which cellular structures</li>
<li>Solution: Side-by-side multi-channel rendering with synchronized playback</li>
<li>Outcome: Rapid visual screening before quantitative analysis</li>
</ul>
<h3 id="developmental-biology">Developmental Biology</h3>
<p><strong>Use Case:</strong> Embryonic development over 48-hour time course</p>
<ul>
<li>5D dataset: Terabyte-scale time-lapse, whole-organism volume</li>
<li>Challenge: Understanding coordinated cell movements during morphogenesis</li>
<li>Solution: Faster-than-real-time playback with cell tracking overlay</li>
<li>Outcome: Human observer spots unexpected patterns, refines tracking algorithm</li>
</ul>
<h3 id="method-validation">Method Validation</h3>
<p><strong>Use Case:</strong> Validating new segmentation algorithm</p>
<ul>
<li>Visual inspection: Does the algorithm segment correctly?</li>
<li>Polygon overlay: Compare algorithm output to expert annotations</li>
<li>Multi-angle rotation: Verify boundaries make sense in 3D</li>
<li>Outcome: Caught edge cases where algorithm failed, improved before publication</li>
</ul>
<hr/>
<h2 id="integration-with-matlab-accessibility-is-usability">Integration with MATLAB: Accessibility is Usability</h2>
<p>A powerful tool that’s inaccessible is useless. The Direct 5D Viewer is designed for <strong>seamless integration with existing scientific workflows</strong>.</p>
<h3 id="matlab-as-the-scientific-lingua-franca">MATLAB as the Scientific Lingua Franca</h3>
<p>Why MATLAB integration matters:</p>
<ul>
<li><strong>Ubiquitous in research</strong> - Computational biologists, neuroscientists, physicists all use MATLAB</li>
<li><strong>Unified workflow</strong> - Load data, process, analyze, visualize—all in one environment</li>
<li><strong>Prototyping speed</strong> - Researchers can test ideas quickly without learning new tools</li>
<li><strong>Reproducibility</strong> - Scripts document exact visualization parameters used</li>
</ul>
<h3 id="example-workflow-pseudocode">Example Workflow (Pseudocode)</h3>
<p>The following illustrates the conceptual workflow—actual function names and APIs may vary:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8;overflow-x:auto" tabindex="0" data-language="matlab"><code><span class="line"><span style="color:#6A737D">% Load 5D microscopy data</span></span>
<span class="line"><span style="color:#E1E4E8">data = loadImageData(</span><span style="color:#9ECBFF">&#39;experiment_001.tif&#39;</span><span style="color:#E1E4E8">);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D">% Process with Hydra (deconvolution, filtering)</span></span>
<span class="line"><span style="color:#E1E4E8">processed = Hydra.deconvolve(data);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D">% Segment cells</span></span>
<span class="line"><span style="color:#E1E4E8">labels = segmentCells(processed);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D">% Visualize with Direct 5D Viewer</span></span>
<span class="line"><span style="color:#E1E4E8">viewer = Direct5DViewer(processed);</span></span>
<span class="line"><span style="color:#E1E4E8">viewer.overlayPolygons(labels);  </span><span style="color:#6A737D">% Show segmentation</span></span>
<span class="line"><span style="color:#E1E4E8">viewer.setColormap([</span><span style="color:#79B8FF">1</span><span style="color:#79B8FF"> 0</span><span style="color:#79B8FF"> 0</span><span style="color:#E1E4E8">; </span><span style="color:#79B8FF">0</span><span style="color:#79B8FF"> 1</span><span style="color:#79B8FF"> 0</span><span style="color:#E1E4E8">]);  </span><span style="color:#6A737D">% Red/green channels</span></span>
<span class="line"><span style="color:#E1E4E8">viewer.enableStereo();  </span><span style="color:#6A737D">% Stereoscopic viewing</span></span>
<span class="line"><span style="color:#E1E4E8">viewer.play();  </span><span style="color:#6A737D">% Time-lapse playback</span></span>
<span class="line"></span></code></pre>
<p><strong>Result:</strong> From raw data to validated visualization in minutes, not hours.</p>
<hr/>
<h2 id="technical-highlights">Technical Highlights</h2>
<h3 id="performance-optimization">Performance Optimization</h3>
<p><strong>Faster-Than-Real-Time Playback:</strong></p>
<ul>
<li>DirectX GPU pipeline achieves 60+ FPS on terabyte-scale datasets</li>
<li>Asynchronous data streaming hides latency</li>
<li>Multi-threaded rendering and data loading</li>
</ul>
<p><strong>Memory Efficiency:</strong></p>
<ul>
<li>Intelligent tiling loads only visible data</li>
<li>Automatic level-of-detail adjustment</li>
<li>GPU texture compression for larger datasets</li>
</ul>
<p><strong>Interactive Responsiveness:</strong></p>
<ul>
<li>&lt;16ms frame time for smooth rotation</li>
<li>Instant parameter updates (colormap, contrast, lighting)</li>
<li>Real-time polygon overlay rendering</li>
</ul>
<h3 id="rendering-innovations">Rendering Innovations</h3>
<p><strong>Object Occlusion:</strong></p>
<ul>
<li>Proper depth testing prevents false adjacency</li>
<li>Z-buffer management for millions of triangles (polygon overlays)</li>
<li>Transparency and alpha blending for multi-object visualization</li>
</ul>
<p><strong>Stereoscopic 3D:</strong></p>
<ul>
<li>Side-by-side or anaglyph rendering modes</li>
<li>Adjustable stereo separation for different display types</li>
<li>Reduced vergence-accommodation conflict through proper depth cues</li>
</ul>
<p><strong>Multi-Channel Compositing:</strong></p>
<ul>
<li>Hardware-accelerated blending of up to 5 fluorescence channels</li>
<li>Per-channel color mapping and intensity adjustment</li>
<li>Spectral unmixing for overlapping emission spectra</li>
</ul>
<hr/>
<h2 id="project-evolution--status">Project Evolution &amp; Status</h2>
<h3 id="release-history">Release History</h3>
<p><strong>v2.0 (December 2024)</strong> - Latest stable release</p>
<ul>
<li>Enhanced MATLAB integration</li>
<li>Improved memory management for larger datasets</li>
<li>Additional shader effects</li>
</ul>
<p><strong>v1.x Series</strong> - Initial public releases</p>
<ul>
<li>Core DirectX rendering engine</li>
<li>MATLAB MEX interface</li>
<li>Basic polygon overlay support</li>
</ul>
<h3 id="development-activity">Development Activity</h3>
<ul>
<li><strong>607 commits</strong> - Active, sustained development</li>
<li><strong>Created August 2018</strong> - 6+ years of refinement</li>
<li><strong>4 open issues</strong> - Ongoing maintenance and feature requests</li>
</ul>
<h3 id="associated-projects">Associated Projects</h3>
<p>Part of the <strong>hydraimageprocessor.com</strong> ecosystem:</p>
<ul>
<li><a href="./hydra">Hydra Image Processor</a> - GPU-accelerated preprocessing</li>
<li><a href="./janelia">Janelia Research Campus work</a> - Real-world deployment in cutting-edge microscopy labs</li>
</ul>
<hr/>
<h2 id="design-principles-lessons-learned">Design Principles: Lessons Learned</h2>
<h3 id="1-accessibility-trumps-power">1. Accessibility Trumps Power</h3>
<p>A visualization tool with 100 features that requires a week to learn will be abandoned. Direct 5D Viewer prioritizes:</p>
<ul>
<li>Default settings that “just work” for most data</li>
<li>MATLAB integration so users stay in familiar environment</li>
<li>Incremental complexity (basic viewing is easy, advanced features available when needed)</li>
</ul>
<h3 id="2-show-dont-tell">2. Show, Don’t Tell</h3>
<p>Numbers alone don’t convey understanding. Example:</p>
<ul>
<li>“Cell volume changed by 23% over 10 minutes” ← Abstract</li>
<li><strong>Visual playback showing the cell expanding</strong> ← Immediate understanding</li>
</ul>
<p>The viewer emphasizes <strong>direct visualization</strong> over quantitative summaries (though both are important).</p>
<h3 id="3-validate-early-validate-often">3. Validate Early, Validate Often</h3>
<p>Don’t wait until analysis is complete to visualize results. The workflow should be:</p>
<ol>
<li>Load data → visualize immediately</li>
<li>Run algorithm → overlay results → validate</li>
<li>Iterate → visualize again</li>
<li>Publish only after visual confirmation</li>
</ol>
<p>This catches errors early when they’re cheap to fix.</p>
<h3 id="4-leverage-human-strengths">4. Leverage Human Strengths</h3>
<p>Don’t make humans do what computers excel at (counting pixels, measuring distances). Don’t make computers do what humans excel at (recognizing patterns, judging biological plausibility). Design tools that create partnerships.</p>
<h3 id="5-performance-enables-insight">5. Performance Enables Insight</h3>
<p>Slow visualization kills exploration. If rotating the view takes 5 seconds, users won’t explore. If it’s instant, they’ll look from every angle and discover patterns they’d otherwise miss.</p>
<p><strong>Target: 60 FPS</strong> - Anything less feels sluggish. Anything more is wasted computation.</p>
<hr/>
<h2 id="technical-architecture">Technical Architecture</h2>
<h3 id="gpu-accelerated-rendering-directx-pipeline">GPU-Accelerated Rendering: DirectX Pipeline</h3>
<p><strong>Why DirectX?</strong></p>
<ul>
<li>Native Windows GPU access with minimal overhead</li>
<li>Mature shading pipeline for complex lighting models</li>
<li>Efficient memory management for terabyte-scale datasets</li>
</ul>
<p><strong>Technology Stack:</strong></p>
<ul>
<li><strong>C++ (79%)</strong> - Core rendering engine and data pipeline</li>
<li><strong>HLSL (High-Level Shader Language)</strong> - GPU shader programming for custom lighting/coloring</li>
<li><strong>MATLAB Interface (16%)</strong> - MEX bindings for seamless integration</li>
<li><strong>CMake</strong> - Cross-configuration build system</li>
</ul>
<h3 id="data-pipeline-from-microscope-to-gpu">Data Pipeline: From Microscope to GPU</h3>
<p>The challenge: Modern microscopy datasets are <strong>terabyte-scale</strong>. GPUs have limited memory (~24GB on high-end cards). How do you visualize data that won’t fit?</p>
<p><strong>Solution: Integration with Hydra Image Processor</strong></p>
<p><a href="./hydra">Hydra</a> provides:</p>
<ul>
<li>Intelligent data tiling and streaming</li>
<li>On-the-fly resampling for multi-resolution viewing</li>
<li>GPU memory management and automatic data transfer</li>
<li>Preprocessing (deconvolution, filtering) before visualization</li>
</ul>
<p>This partnership enables:</p>
<ul>
<li><strong>Near-complete dataset loading</strong> - Smart tiling keeps relevant data GPU-resident</li>
<li><strong>Interactive performance</strong> - Faster-than-real-time playback even on massive datasets</li>
<li><strong>Unified pipeline</strong> - Process and visualize without leaving MATLAB</li>
</ul>
<h3 id="shader-programming-custom-visual-encoding">Shader Programming: Custom Visual Encoding</h3>
<p>The viewer uses <strong>custom HLSL shaders</strong> to implement advanced visualization techniques:</p>
<p><strong>Volume Rendering Shaders:</strong></p>
<ul>
<li>Ray-casting through 3D volumes with proper alpha blending</li>
<li>Maximum intensity projection (when appropriate)</li>
<li>Isosurface extraction for object boundaries</li>
</ul>
<p><strong>Lighting Models:</strong></p>
<ul>
<li>Phong shading for surface detail</li>
<li>Ambient occlusion for depth cues</li>
<li>Custom lighting to emphasize biological structures</li>
</ul>
<p><strong>Multi-channel Compositing:</strong></p>
<ul>
<li>Blend multiple fluorescence channels with independent colormaps</li>
<li>Linear unmixing for spectral overlap correction</li>
<li>Adjustable opacity and contrast per channel</li>
</ul>
<hr/>
<h2 id="future-directions">Future Directions</h2>
<h3 id="short-term-enhancements">Short-Term Enhancements</h3>
<ul>
<li><strong>Cloud rendering</strong> - Enable remote visualization for users without GPU workstations</li>
<li><strong>VR integration</strong> - Native support for Oculus/Vive for true immersive 3D</li>
<li><strong>Collaborative viewing</strong> - Multiple users viewing/annotating same dataset in real-time</li>
</ul>
<h3 id="medium-term-features">Medium-Term Features</h3>
<ul>
<li><strong>Python API</strong> - Extend beyond MATLAB to Python scientific stack</li>
<li><strong>Web-based viewer</strong> - WebGPU port for browser-based visualization</li>
<li><strong>AI-assisted exploration</strong> - Suggest interesting timepoints/regions based on learned patterns</li>
</ul>
<h3 id="long-term-vision">Long-Term Vision</h3>
<ul>
<li><strong>Real-time microscope integration</strong> - Visualize data as it’s being acquired, guide experiments adaptively</li>
<li><strong>Multi-modal fusion</strong> - Combine microscopy with other data types (electrophysiology, mass spec imaging)</li>
<li><strong>Automated insight detection</strong> - Flag unusual patterns for human review</li>
</ul>
<hr/>
<h2 id="publications--recognition">Publications &amp; Recognition</h2>
<p>The Direct 5D Viewer has been instrumental in enabling scientific discoveries across cellular biology, cancer research, and systems-level imaging. Key publications utilizing this visualization platform:</p>
<h3 id="nature--nature-communications">Nature &amp; Nature Communications</h3>
<p><a href="https://doi.org/10.1038/s41586-021-03309-5"><strong>Actin cables and comet tails organize mitochondrial networks in mitosis</strong></a>. <em>Nature</em> 2021</p>
<ul>
<li>Revealed how mitochondrial networks reorganize during cell division</li>
<li>Visualized actin-mediated mitochondrial transport in 3D+time</li>
<li>Direct 5D Viewer enabled validation of automated tracking across division events</li>
</ul>
<p><a href="http://rdcu.be/sZxu"><strong>Applying Systems-level Spectral Imaging and Analysis to Reveal the Organelle Interactome</strong></a>. <em>Nature</em> 2017</p>
<ul>
<li>Systems-level analysis of organelle spatial relationships</li>
<li>Multi-channel visualization of 10+ organelle markers simultaneously</li>
<li>Interactive exploration critical for understanding spatial organization patterns</li>
</ul>
<p><a href="http://www.nature.com/articles/ncomms13730?WT.feed_name=subjects_biological-sciences"><strong>A Neuronal Network Of Mitochondrial Dynamics Regulates Metastasis</strong></a>. <em>Nature Communications</em> 2016</p>
<ul>
<li>Discovered mitochondrial dynamics network regulating cancer metastasis</li>
<li>Time-lapse visualization of mitochondrial motility patterns</li>
<li>Polygon overlay validation of automated mitochondrial tracking</li>
</ul>
<h3 id="ieee-transactions-on-medical-imaging">IEEE Transactions on Medical Imaging</h3>
<p><a href="https://doi.org/10.1109/TMI.2018.2874104"><strong>Separating Touching Cells using Pixel Replicated Elliptical Shape Models</strong></a>. <em>IEEE Transactions on Medical Imaging</em> 2018</p>
<ul>
<li>Novel segmentation algorithm for touching/overlapping cells</li>
<li>Direct 5D Viewer provided visual validation of segmentation boundaries</li>
<li>Immediate feedback loop: segment → visualize → refine → validate</li>
</ul>
<h3 id="impact">Impact</h3>
<p><strong>Used by 170+ scientists</strong> at HHMI Janelia Research Campus and collaborating institutions worldwide</p>
<p><strong>Enabled discoveries</strong> in cellular dynamics, organelle interactions, cancer biology, and developmental processes</p>
<p><strong>Visual validation</strong> prevented algorithmic errors that would have led to false biological conclusions</p>
<hr/>
<h2 id="links--resources">Links &amp; Resources</h2>
<p><strong>GitHub Repository:</strong> <a href="https://github.com/ericwait/direct-5D-viewer">https://github.com/ericwait/direct-5D-viewer</a></p>
<p><strong>Latest Release:</strong> v2.0 (December 2024)</p>
<p><strong>Related Projects:</strong></p>
<ul>
<li><a href="./hydra">Hydra Image Processor</a> - GPU-accelerated preprocessing pipeline</li>
<li><a href="./janelia">Janelia Research Campus</a> - Real-world deployment and case studies</li>
</ul>
<p><strong>Technologies:</strong></p>
<ul>
<li>C++, DirectX, HLSL</li>
<li>MATLAB MEX interface</li>
<li>CMake build system</li>
</ul>
<p><strong>Website:</strong> <a href="http://www.hydraimageprocessor.com">hydraimageprocessor.com</a></p>
<hr/>
<h2 id="how-this-connects">How This Connects</h2>
<p><strong>Human-Centered AI Philosophy:</strong> See how this approach extends across all my work → <a href="../#-human-centered-ai-design">Home page</a></p>
<p><strong>Visual Perception Meets ML:</strong> Explore how photography training informs technical work → <a href="../photos#from-lens-to-algorithm-the-bridge">Photography</a></p>
<p><strong>Technical Foundation:</strong> Built on GPU acceleration infrastructure → <a href="./hydra">Hydra Image Processor</a></p>
<p><strong>Deployed at Scale:</strong> Used in hypothesis-driven research → <a href="./janelia">Janelia Research Campus</a></p>
<p><strong>Design Philosophy:</strong> Learn about building systems that amplify human capability → <a href="../about#leadership-philosophy-multiply-impact-through-others">About</a></p>
<p><strong>Building What Lasts:</strong> Explore long-term development practices → <a href="./matlab-utilities">MATLAB Utilities</a></p> </div> </div> </article>  </main> <footer class="bg-gray-50 dark:bg-gray-900 border-t border-gray-200 dark:border-gray-800"> <div class="container py-12"> <div class="grid grid-cols-1 md:grid-cols-3 gap-8"> <!-- About --> <div> <h3 class="text-lg font-bold mb-4">Eric Wait</h3> <p class="text-gray-600 dark:text-gray-400 text-sm">
Principal Data Scientist | GPU/ML Systems Engineer | Physics-Informed AI Specialist
</p> </div> <!-- Quick Links --> <div> <h3 class="text-lg font-bold mb-4">Quick Links</h3> <ul class="space-y-2"> <li><a href="/about" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 text-sm transition-colors">About</a></li> <li><a href="/projects" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 text-sm transition-colors">Projects</a></li> <li><a href="/publications" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 text-sm transition-colors">Publications</a></li> <li><a href="/photography" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 text-sm transition-colors">Photography</a></li> </ul> </div> <!-- Social --> <div> <h3 class="text-lg font-bold mb-4">Connect</h3> <div class="flex space-x-4"> <a href="https://github.com/ericwait" target="_blank" rel="noopener noreferrer" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 transition-colors" aria-label="GitHub"> <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"> <path fill-rule="evenodd" d="M12 2C6.477 2 2 6.484 2 12.017c0 4.425 2.865 8.18 6.839 9.504.5.092.682-.217.682-.483 0-.237-.008-.868-.013-1.703-2.782.605-3.369-1.343-3.369-1.343-.454-1.158-1.11-1.466-1.11-1.466-.908-.62.069-.608.069-.608 1.003.07 1.531 1.032 1.531 1.032.892 1.53 2.341 1.088 2.91.832.092-.647.35-1.088.636-1.338-2.22-.253-4.555-1.113-4.555-4.951 0-1.093.39-1.988 1.029-2.688-.103-.253-.446-1.272.098-2.65 0 0 .84-.27 2.75 1.026A9.564 9.564 0 0112 6.844c.85.004 1.705.115 2.504.337 1.909-1.296 2.747-1.027 2.747-1.027.546 1.379.202 2.398.1 2.651.64.7 1.028 1.595 1.028 2.688 0 3.848-2.339 4.695-4.566 4.943.359.309.678.92.678 1.855 0 1.338-.012 2.419-.012 2.747 0 .268.18.58.688.482A10.019 10.019 0 0022 12.017C22 6.484 17.522 2 12 2z" clip-rule="evenodd"></path> </svg>    </a><a href="https://www.linkedin.com/in/ericwaitinfo/" target="_blank" rel="noopener noreferrer" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 transition-colors" aria-label="LinkedIn">  <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"> <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path> </svg>   </a><a href="https://twitter.com/ericwait" target="_blank" rel="noopener noreferrer" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 transition-colors" aria-label="Twitter">   <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"> <path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"></path> </svg>  </a><a href="https://www.instagram.com/eric.wait/" target="_blank" rel="noopener noreferrer" class="text-gray-600 dark:text-gray-400 hover:text-primary-600 dark:hover:text-primary-400 transition-colors" aria-label="Instagram">    <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"> <path d="M12 2.163c3.204 0 3.584.012 4.85.07 3.252.148 4.771 1.691 4.919 4.919.058 1.265.069 1.645.069 4.849 0 3.205-.012 3.584-.069 4.849-.149 3.225-1.664 4.771-4.919 4.919-1.266.058-1.644.07-4.85.07-3.204 0-3.584-.012-4.849-.07-3.26-.149-4.771-1.699-4.919-4.92-.058-1.265-.07-1.644-.07-4.849 0-3.204.013-3.583.07-4.849.149-3.227 1.664-4.771 4.919-4.919 1.266-.057 1.645-.069 4.849-.069zm0-2.163c-3.259 0-3.667.014-4.947.072-4.358.2-6.78 2.618-6.98 6.98-.059 1.281-.073 1.689-.073 4.948 0 3.259.014 3.668.072 4.948.2 4.358 2.618 6.78 6.98 6.98 1.281.058 1.689.072 4.948.072 3.259 0 3.668-.014 4.948-.072 4.354-.2 6.782-2.618 6.979-6.98.059-1.28.073-1.689.073-4.948 0-3.259-.014-3.667-.072-4.947-.196-4.354-2.617-6.78-6.979-6.98-1.281-.059-1.69-.073-4.949-.073zm0 5.838c-3.403 0-6.162 2.759-6.162 6.162s2.759 6.163 6.162 6.163 6.162-2.759 6.162-6.163c0-3.403-2.759-6.162-6.162-6.162zm0 10.162c-2.209 0-4-1.79-4-4 0-2.209 1.791-4 4-4s4 1.791 4 4c0 2.21-1.791 4-4 4zm6.406-11.845c-.796 0-1.441.645-1.441 1.44s.645 1.44 1.441 1.44c.795 0 1.439-.645 1.439-1.44s-.644-1.44-1.439-1.44z"></path> </svg> </a> </div> </div> </div> <!-- Copyright --> <div class="mt-8 pt-8 border-t border-gray-200 dark:border-gray-800 text-center"> <p class="text-sm text-gray-600 dark:text-gray-400">
© 2025 Eric Wait. All rights reserved.
</p> </div> </div> </footer> </body></html> 